# Context-Aware-Prompt-Architect

# Prompt Architect

<div align="center">

**Context-Aware Prompt Enhancer for Developers**

Powered by local Ollama models

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Electron](https://img.shields.io/badge/Electron-28.0-blue.svg)](https://www.electronjs.org/)
[![React](https://img.shields.io/badge/React-18.2-blue.svg)](https://reactjs.org/)
[![TypeScript](https://img.shields.io/badge/TypeScript-5.3-blue.svg)](https://www.typescriptlang.org/)

[English](#english) | [TÃ¼rkÃ§e](#tÃ¼rkÃ§e) | [Deutsch](#deutsch) | [Suomi](#suomi)

</div>

---

## English

### âœ¨ Features

- ğŸ¯ **Context-Aware Prompt Refinement**: Analyzes your project structure and tech stack to create optimized prompts
- ğŸ¤– **Local AI Models**: Works entirely with local Ollama models - no data leaves your machine
- ğŸ“ **Project Analysis**: Automatically detects tech stack, config files, and project structure
- ğŸŒ **Multi-Language UI Support**: Full UI support for English, Turkish, German, and Finnish
- ğŸ¨ **Modern UI**: Clean, professional interface with dark/light theme support
- âš¡ **Fast & Efficient**: Built with Electron, React, and Vite for optimal performance
- ğŸ”’ **Privacy First**: All processing happens locally - your code never leaves your computer
- ğŸ“š **Prompt History**: View and reload previous prompts with full history management
- ğŸ›‘ **Generation Control**: Stop ongoing AI generation at any time
- ğŸ’» **Cross-Platform**: Supports macOS (Intel & Apple Silicon) and Windows (x64 & ia32)
- ğŸ¨ **Professional Logo**: Custom-designed logo with modern gradient aesthetics

### ğŸš€ Quick Start

#### Prerequisites

- Node.js 18+ and npm
- [Ollama](https://ollama.ai/) installed and running
- At least one Ollama model installed (e.g., `ollama pull llama3.2`)

#### Installation

1. Clone the repository:
```bash
git clone https://github.com/yourusername/prompt-architect.git
cd prompt-architect
```

2. Install dependencies:
```bash
npm install
```

3. Start Ollama (if not already running):
```bash
ollama serve
```

4. Run the application:
```bash
npm run electron:dev
```

### ğŸ“¦ Building for Production

#### Icon OluÅŸturma (macOS)

Uygulama iÃ§in logo/icon oluÅŸturmak iÃ§in:

```bash
npm run generate:icon
```

DetaylÄ± bilgi iÃ§in [ICON_GUIDE.md](ICON_GUIDE.md) dosyasÄ±na bakÄ±n.

#### Development Build
```bash
npm run electron:dev
```

#### Production Build

#### macOS iÃ§in Build
```bash
npm run electron:build:mac
```

veya sadece DMG dosyasÄ± iÃ§in:
```bash
npm run electron:build:mac:dmg
```

#### Windows iÃ§in Build
```bash
npm run electron:build:win
```

veya sadece NSIS installer iÃ§in:
```bash
npm run electron:build:win:nsis
```

#### TÃ¼m Platformlar iÃ§in Build
```bash
npm run electron:build
```

The built application will be in the `release/` directory.

**Kurulum Rehberleri:**
- **macOS:** DetaylÄ± kurulum talimatlarÄ± iÃ§in [BUILD_MACOS.md](BUILD_MACOS.md) dosyasÄ±na bakÄ±n.
- **Windows:** DetaylÄ± kurulum talimatlarÄ± iÃ§in [BUILD_WINDOWS.md](BUILD_WINDOWS.md) dosyasÄ±na bakÄ±n.

**Build Test:**
- Build'lerin Ã§alÄ±ÅŸÄ±p Ã§alÄ±ÅŸmadÄ±ÄŸÄ±nÄ± kontrol etmek iÃ§in [TESTING.md](TESTING.md) dosyasÄ±na bakÄ±n.
- GitHub Actions otomatik olarak Windows ve macOS build'lerini test eder (tag/release oluÅŸturulduÄŸunda).

### ğŸ¯ Usage

1. **Select a Project Folder**: Click "Select Folder" and choose your project directory
2. **Choose a Model**: Select an Ollama model from the dropdown
3. **Select Mode**: Choose between "Fast" (quick analysis) or "Plan" (deep analysis)
4. **Write Your Prompt**: Enter a raw prompt describing what you want to build
5. **Refine**: Click "Refine Prompt" to get a context-aware, detailed prompt
6. **Copy & Use**: Copy the refined prompt and use it with your AI coding assistant
7. **Review History**: View and reload previous prompts from the history section

### ğŸ—ï¸ Project Structure

```
prompt-architect/
â”œâ”€â”€ electron/              # Electron main process
â”‚   â”œâ”€â”€ main.ts           # Main process (window management, IPC)
â”‚   â””â”€â”€ preload.ts        # Preload script (secure API exposure)
â”œâ”€â”€ src/                   # React application
â”‚   â”œâ”€â”€ components/       # UI components
â”‚   â”œâ”€â”€ services/         # Services (Ollama integration)
â”‚   â”œâ”€â”€ stores/           # Zustand state management
â”‚   â”œâ”€â”€ hooks/            # Custom React hooks
â”‚   â”œâ”€â”€ i18n/             # Internationalization
â”‚   â””â”€â”€ utils/            # Utility functions
â”œâ”€â”€ dist/                  # Build outputs
â”œâ”€â”€ dist-electron/         # Electron build outputs
â””â”€â”€ release/               # Production builds
```

### ğŸ”§ Configuration

#### Ollama URL

By default, the app connects to `http://localhost:11434`. To change this, modify `src/stores/useAppStore.ts`:
```typescript
ollamaBaseURL: 'http://your-ollama-url:11434'
```

### ğŸ› ï¸ Development

#### Tech Stack

- **Electron**: Desktop application framework
- **React**: UI library
- **TypeScript**: Type safety
- **Vite**: Build tool and dev server
- **TailwindCSS**: Styling
- **Zustand**: State management
- **Axios**: HTTP client for Ollama API
- **i18n**: Custom internationalization system

#### Supported Platforms

- âœ… **macOS**: 10.15+ (Intel x64 & Apple Silicon arm64)
- âœ… **Windows**: 10+ (x64 & ia32)
- âœ… **Linux**: AppImage (future support)

#### Scripts

- `npm run dev`: Start Vite dev server
- `npm run electron:dev`: Start Electron in development mode
- `npm run build`: Build React app
- `npm run electron:build`: Build Electron app for all platforms
- `npm run electron:build:mac`: Build for macOS only
- `npm run electron:build:win`: Build for Windows only
- `npm run generate:icon`: Generate macOS icon
- `npm run generate:icon:win`: Generate Windows icon
- `npm run lint`: Run ESLint

### ğŸ¤ Contributing

Contributions are welcome! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

### ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

### ğŸ™ Acknowledgments

- [Ollama](https://ollama.ai/) for providing local LLM capabilities
- [Electron](https://www.electronjs.org/) for the desktop framework
- [React](https://reactjs.org/) and [Vite](https://vitejs.dev/) for the amazing developer experience

### ğŸ“§ Support

If you encounter any issues or have questions, please open an issue on GitHub.

---

## TÃ¼rkÃ§e

### âœ¨ Ã–zellikler

- ğŸ¯ **BaÄŸlam FarkÄ±nda Prompt Ä°yileÅŸtirme**: Proje yapÄ±nÄ±zÄ± ve teknoloji yÄ±ÄŸÄ±nÄ±nÄ±zÄ± analiz ederek optimize edilmiÅŸ prompt'lar oluÅŸturur
- ğŸ¤– **Yerel AI Modelleri**: Tamamen yerel Ollama modelleriyle Ã§alÄ±ÅŸÄ±r - verileriniz makinenizden Ã§Ä±kmaz
- ğŸ“ **Proje Analizi**: Teknoloji yÄ±ÄŸÄ±nÄ±, config dosyalarÄ± ve proje yapÄ±sÄ±nÄ± otomatik olarak tespit eder
- ğŸŒ **Ã‡oklu Dil DesteÄŸi**: Ä°ngilizce, TÃ¼rkÃ§e, Almanca ve Fince iÃ§in tam UI desteÄŸi
- ğŸ¨ **Modern ArayÃ¼z**: KaranlÄ±k/aydÄ±nlÄ±k tema desteÄŸi ile temiz, profesyonel arayÃ¼z
- âš¡ **HÄ±zlÄ± ve Verimli**: Optimal performans iÃ§in Electron, React ve Vite ile geliÅŸtirilmiÅŸtir
- ğŸ”’ **Gizlilik Ã–ncelikli**: TÃ¼m iÅŸlemler yerel olarak gerÃ§ekleÅŸir - kodunuz bilgisayarÄ±nÄ±zdan Ã§Ä±kmaz
- ğŸ“š **Prompt GeÃ§miÅŸi**: Ã–nceki prompt'larÄ± gÃ¶rÃ¼ntÃ¼leyin ve yeniden yÃ¼kleyin
- ğŸ›‘ **Ãœretim KontrolÃ¼**: Devam eden AI Ã¼retimini istediÄŸiniz zaman durdurun

### ğŸš€ HÄ±zlÄ± BaÅŸlangÄ±Ã§

#### Gereksinimler

- Node.js 18+ ve npm
- [Ollama](https://ollama.ai/) kurulu ve Ã§alÄ±ÅŸÄ±yor olmalÄ±
- En az bir Ollama modeli kurulu olmalÄ± (Ã¶rn: `ollama pull llama3.2`)

#### Kurulum

1. Depoyu klonlayÄ±n:
```bash
git clone https://github.com/yourusername/prompt-architect.git
cd prompt-architect
```

2. BaÄŸÄ±mlÄ±lÄ±klarÄ± yÃ¼kleyin:
```bash
npm install
```

3. Ollama'yÄ± baÅŸlatÄ±n (zaten Ã§alÄ±ÅŸmÄ±yorsa):
```bash
ollama serve
```

4. UygulamayÄ± Ã§alÄ±ÅŸtÄ±rÄ±n:
```bash
npm run electron:dev
```

### ğŸ“¦ Ãœretim Derlemesi

#### GeliÅŸtirme Derlemesi
```bash
npm run electron:dev
```

#### Ãœretim Derlemesi
```bash
npm run electron:build
```

DerlenmiÅŸ uygulama `release/` dizininde olacaktÄ±r.

### ğŸ¯ KullanÄ±m

1. **Proje KlasÃ¶rÃ¼ SeÃ§in**: "KlasÃ¶r SeÃ§" butonuna tÄ±klayÄ±n ve proje dizininizi seÃ§in
2. **Model SeÃ§in**: Dropdown'dan bir Ollama modeli seÃ§in
3. **Mod SeÃ§in**: "HÄ±zlÄ±" (hÄ±zlÄ± analiz) veya "Plan" (derinlemesine analiz) arasÄ±nda seÃ§im yapÄ±n
4. **Prompt YazÄ±n**: Ne yapmak istediÄŸinizi aÃ§Ä±klayan bir prompt girin
5. **Ä°yileÅŸtir**: "Prompt Ä°yileÅŸtir" butonuna tÄ±klayarak baÄŸlam farkÄ±nda, detaylÄ± bir prompt alÄ±n
6. **Kopyala ve Kullan**: Ä°yileÅŸtirilmiÅŸ prompt'u kopyalayÄ±n ve AI kodlama asistanÄ±nÄ±zla kullanÄ±n
7. **GeÃ§miÅŸi Ä°ncele**: GeÃ§miÅŸ bÃ¶lÃ¼mÃ¼nden Ã¶nceki prompt'larÄ± gÃ¶rÃ¼ntÃ¼leyin ve yeniden yÃ¼kleyin

### ğŸ“ Lisans

Bu proje MIT LisansÄ± altÄ±nda lisanslanmÄ±ÅŸtÄ±r - detaylar iÃ§in [LICENSE](LICENSE) dosyasÄ±na bakÄ±n.

---

## Deutsch

### âœ¨ Funktionen

- ğŸ¯ **Kontextbewusste Prompt-Verfeinerung**: Analysiert Ihre Projektstruktur und Tech-Stack, um optimierte Prompts zu erstellen
- ğŸ¤– **Lokale KI-Modelle**: Funktioniert vollstÃ¤ndig mit lokalen Ollama-Modellen - keine Daten verlassen Ihren Computer
- ğŸ“ **Projektanalyse**: Erkennt automatisch Tech-Stack, Konfigurationsdateien und Projektstruktur
- ğŸŒ **Mehrsprachige UnterstÃ¼tzung**: VollstÃ¤ndige UI-UnterstÃ¼tzung fÃ¼r Englisch, TÃ¼rkisch, Deutsch und Finnisch
- ğŸ¨ **Moderne BenutzeroberflÃ¤che**: Saubere, professionelle OberflÃ¤che mit Dark/Light-Theme-UnterstÃ¼tzung
- âš¡ **Schnell und Effizient**: Entwickelt mit Electron, React und Vite fÃ¼r optimale Leistung
- ğŸ”’ **Datenschutz zuerst**: Alle Verarbeitungen erfolgen lokal - Ihr Code verlÃ¤sst nie Ihren Computer
- ğŸ“š **Prompt-Verlauf**: Zeigen Sie vorherige Prompts an und laden Sie sie neu
- ğŸ›‘ **Generierungssteuerung**: Stoppen Sie laufende KI-Generierungen jederzeit

### ğŸš€ Schnellstart

#### Voraussetzungen

- Node.js 18+ und npm
- [Ollama](https://ollama.ai/) installiert und laufend
- Mindestens ein Ollama-Modell installiert (z.B. `ollama pull llama3.2`)

#### Installation

1. Repository klonen:
```bash
git clone https://github.com/yourusername/prompt-architect.git
cd prompt-architect
```

2. AbhÃ¤ngigkeiten installieren:
```bash
npm install
```

3. Ollama starten (falls nicht bereits laufend):
```bash
ollama serve
```

4. Anwendung ausfÃ¼hren:
```bash
npm run electron:dev
```

### ğŸ“ Lizenz

Dieses Projekt ist unter der MIT-Lizenz lizenziert - siehe [LICENSE](LICENSE) Datei fÃ¼r Details.

---

## Suomi

### âœ¨ Ominaisuudet

- ğŸ¯ **Kontekstitietoinen Prompt-parannus**: Analysoi projektirakenteesi ja teknologiapinon optimoitujen prompttien luomiseksi
- ğŸ¤– **Paikalliset AI-mallit**: Toimii tÃ¤ysin paikallisten Ollama-mallien kanssa - tietosi eivÃ¤t poistu tietokoneeltasi
- ğŸ“ **Projektianalyysi**: Havaitsi automaattisesti teknologiapinon, konfiguraatiotiedostot ja projektirakenteen
- ğŸŒ **Monikielinen tuki**: TÃ¤ydellinen UI-tuki englanniksi, turkiksi, saksaksi ja suomeksi
- ğŸ¨ **Moderni kÃ¤yttÃ¶liittymÃ¤**: Siisti, ammattimainen kÃ¤yttÃ¶liittymÃ¤ tumman/vaalean teeman tuella
- âš¡ **Nopea ja tehokas**: Rakennettu Electronilla, Reactilla ja VitellÃ¤ optimaalista suorituskykyÃ¤ varten
- ğŸ”’ **Yksityisyys ensin**: Kaikki kÃ¤sittely tapahtuu paikallisesti - koodisi ei koskaan poistu tietokoneeltasi
- ğŸ“š **Prompt-historia**: Tarkastele ja lataa uudelleen aiemmat promptit
- ğŸ›‘ **Generoinnin hallinta**: PysÃ¤ytÃ¤ meneillÃ¤Ã¤n oleva AI-generointi milloin tahansa

### ğŸš€ PikakÃ¤yttÃ¶Ã¶notto

#### Edellytykset

- Node.js 18+ ja npm
- [Ollama](https://ollama.ai/) asennettuna ja kÃ¤ynnissÃ¤
- VÃ¤hintÃ¤Ã¤n yksi Ollama-malli asennettuna (esim. `ollama pull llama3.2`)

#### Asennus

1. Kloonaa repository:
```bash
git clone https://github.com/yourusername/prompt-architect.git
cd prompt-architect
```

2. Asenna riippuvuudet:
```bash
npm install
```

3. KÃ¤ynnistÃ¤ Ollama (jos ei jo kÃ¤ynnissÃ¤):
```bash
ollama serve
```

4. Suorita sovellus:
```bash
npm run electron:dev
```

### ğŸ“ Lisenssi

TÃ¤mÃ¤ projekti on lisensoitu MIT-lisenssillÃ¤ - katso [LICENSE](LICENSE) tiedosto yksityiskohtia varten.

---

Made with â¤ï¸ for developers who want better AI prompts

## ğŸ‘¤ Author

**Senol Dogan**

- ğŸŒ Website: [www.senoldogan.dev](https://www.senoldogan.dev)
- ğŸ“§ Email: [contact@senoldogan.dev](mailto:contact@senoldogan.dev)
- ğŸ“± Phone: +358451242459
- ğŸ’» GitHub: [@senoldogann](https://github.com/senoldogann)
